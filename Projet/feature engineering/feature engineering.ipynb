{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project assumes the following initial file structure:\n",
    "\n",
    "```bash\n",
    "./feature_engineering                         \n",
    "|   preprocessing.ipynb                       \n",
    "|                                             \n",
    "\\---datasets                                  \n",
    "    |                                         \n",
    "    +---EmoDB                                 \n",
    "    |   |   erkennung.txt                     \n",
    "    |   |   erklaerung.txt                    \n",
    "    |   |                                     \n",
    "    |   +---lablaut                           \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   +---labsilb                           \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   +---silb                              \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   \\---wav                               \n",
    "    |           03a01Fa.wav                   \n",
    "    |           03a01Nc.wav                   \n",
    "    |           ...                           \n",
    "    |                                         \n",
    "    \\---RAVDESS                               \n",
    "        |                                     \n",
    "        +---song                              \n",
    "        |   +---Actor_01                      \n",
    "        |   |       03-02-01-01-01-01-01.wav  \n",
    "        |   |       03-02-01-01-01-02-01.wav  \n",
    "        |   |       ...                       \n",
    "        |   |                                 \n",
    "        |   +---Actor_02                      \n",
    "        |   |       03-02-01-01-01-01-02.wav  \n",
    "        |   |       03-02-01-01-01-02-02.wav  \n",
    "        |   |       ...                       \n",
    "        |   |                                 \n",
    "        |   +---...                           \n",
    "        |   \\---Actor_24                      \n",
    "        |           03-02-01-01-01-01-24.wav  \n",
    "        |           03-02-01-01-01-02-24.wav  \n",
    "        |           ...                       \n",
    "        |                                     \n",
    "        \\---speech                            \n",
    "            +---Actor_01                      \n",
    "            |       03-01-01-01-01-01-01.wav  \n",
    "            |       03-01-01-01-01-02-01.wav  \n",
    "            |       ...                       \n",
    "            +---Actor_02                      \n",
    "            |       03-01-01-01-01-01-02.wav  \n",
    "            |       03-01-01-01-01-02-02.wav  \n",
    "            |       ...                       \n",
    "            |                                 \n",
    "            +---...                           \n",
    "            \\---Actor_24                      \n",
    "                    03-01-01-01-01-01-24.wav  \n",
    "                    03-01-01-01-01-02-24.wav  \n",
    "                    ...                       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import importlib.metadata\n",
    "import os\n",
    "import types\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import librosa  # https://github.com/librosa/librosa/issues/1776\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current module versions in use are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Module</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>librosa</td>\n",
       "      <td>0.10.2.post1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>matplotlib</td>\n",
       "      <td>3.9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numpy</td>\n",
       "      <td>1.26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pandas</td>\n",
       "      <td>2.2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tqdm</td>\n",
       "      <td>4.66.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Module       Version\n",
       "0     librosa  0.10.2.post1\n",
       "1  matplotlib         3.9.2\n",
       "2       numpy        1.26.4\n",
       "3      pandas         2.2.3\n",
       "4        tqdm        4.66.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for dist in importlib.metadata.distributions():\n",
    "    if (\n",
    "        dist.metadata[\"Name\"].lower() in imports\n",
    "        and dist.metadata[\"Name\"].lower() != \"pip\"\n",
    "    ):\n",
    "        requirements.append((dist.metadata[\"Name\"], dist.version))\n",
    "\n",
    "pd.DataFrame(requirements, columns=[\"Module\", \"Version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./datasets\"\n",
    "SR = 8000\n",
    "SEGMENT_DURATION = 3\n",
    "PAD_ZERO = True\n",
    "TRUNCATE = True\n",
    "RAVDESS_PATH = os.path.join(DATA_PATH, \"RAVDESS\")\n",
    "CODED_RAVDESS = {\n",
    "    \"modalities\": {\"01\": \"full-AV\", \"02\": \"video-only\", \"03\": \"audio-only\"},\n",
    "    \"vocal_channels\": {\"01\": \"speech\", \"02\": \"song\"},\n",
    "    \"emotions\": {\n",
    "        \"01\": \"neutral\",\n",
    "        \"02\": \"calm\",\n",
    "        \"03\": \"happy\",\n",
    "        \"04\": \"sad\",\n",
    "        \"05\": \"angry\",\n",
    "        \"06\": \"fearful\",\n",
    "        \"07\": \"disgust\",\n",
    "        \"08\": \"surprised\",\n",
    "    },\n",
    "    \"emotional_intensities\": {\"01\": \"normal\", \"02\": \"strong\"},\n",
    "    \"statements\": {\n",
    "        \"01\": \"Kids are talking by the door\",\n",
    "        \"02\": \"Dogs are sitting by the door\",\n",
    "    },\n",
    "    \"repetitions\": {\"01\": \"1st repetition\", \"02\": \"2nd repetition\"},\n",
    "}\n",
    "EMODB_PATH = os.path.join(DATA_PATH, \"EmoDB\")\n",
    "CODED_EMODB = {\n",
    "    \"actors\": {\n",
    "        \"03\": (\"Male\", 31),\n",
    "        \"08\": (\"Female\", 34),\n",
    "        \"09\": (\"Female\", 21),\n",
    "        \"10\": (\"Male\", 32),\n",
    "        \"11\": (\"Male\", 26),\n",
    "        \"12\": (\"Male\", 30),\n",
    "        \"13\": (\"Female\", 32),\n",
    "        \"14\": (\"Female\", 35),\n",
    "        \"15\": (\"Male\", 25),\n",
    "        \"16\": (\"Female\", 31),\n",
    "    },\n",
    "    \"texts\": {\n",
    "        \"a01\": \"Der Lappen liegt auf dem Eisschrank.\",\n",
    "        \"a02\": \"Das will sie am Mittwoch abgeben.\",\n",
    "        \"a04\": \"Heute abend könnte ich es ihm sagen.\",\n",
    "        \"a05\": \"Das schwarze Stück Papier befindet sich da oben neben dem Holzstück.\",\n",
    "        \"a07\": \"In sieben Stunden wird es soweit sein.\",\n",
    "        \"b01\": \"Was sind denn das für Tüten, die da unter dem Tisch stehen?\",\n",
    "        \"b02\": \"Sie haben es gerade hochgetragen und jetzt gehen sie wieder runter.\",\n",
    "        \"b03\": \"An den Wochenenden bin ich jetzt immer nach Hause gefahren und habe Agnes besucht.\",\n",
    "        \"b09\": \"Ich will das eben wegbringen und dann mit Karl was trinken gehen.\",\n",
    "        \"b10\": \"Die wird auf dem Platz sein, wo wir sie immer hinlegen.\",\n",
    "    },\n",
    "    \"emotions\": {\n",
    "        \"W\": \"Anger\",\n",
    "        \"L\": \"Boredom\",\n",
    "        \"E\": \"Disgust\",\n",
    "        \"A\": \"Anxiety/Fear\",\n",
    "        \"F\": \"Happiness\",\n",
    "        \"T\": \"Sadness\",\n",
    "        \"N\": \"Neutral\",\n",
    "    },\n",
    "}\n",
    "CHUNK_SIZE = 10\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_vocals(\n",
    "    speech: np.ndarray,\n",
    "    sr: int = SR,\n",
    "    filter_duration: float = 0.75,\n",
    "    top_db: int = 60,\n",
    ") -> np.ndarray:\n",
    "    S_full, phase = librosa.magphase(librosa.stft(speech))\n",
    "    S_filter = librosa.decompose.nn_filter(\n",
    "        S_full,\n",
    "        aggregate=np.median,\n",
    "        metric=\"cosine\",\n",
    "        width=int(librosa.time_to_frames(filter_duration, sr=sr)),\n",
    "    )\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter, 10 * S_filter, power=2)\n",
    "    speech = librosa.istft(mask_v * S_full * phase)\n",
    "    indexes = librosa.effects.split(speech, top_db=top_db)\n",
    "    speech = np.array(\n",
    "        [num for arr in (speech[i[0] : i[1]] for i in indexes) for num in arr.tolist()]\n",
    "    )\n",
    "\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ravdess(\n",
    "    ravdess_path: str = RAVDESS_PATH,\n",
    "    sr: int = SR,\n",
    "    segment_duration: float = SEGMENT_DURATION,\n",
    "    filter_duration: float = 0.75,\n",
    "    top_db: int = 60,\n",
    "    pad_zero: bool = PAD_ZERO,\n",
    "    truncate: bool = TRUNCATE,\n",
    "    coded_ravdess: Dict = CODED_RAVDESS,\n",
    "    persistency: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List]:\n",
    "\n",
    "    if persistency:\n",
    "        with open(os.path.join(ravdess_path, \"data.tsv\"), mode=\"w\") as f:\n",
    "            f.truncate()\n",
    "\n",
    "    data = {\n",
    "        \"File Name\": [],\n",
    "        \"Duration\": [],\n",
    "        \"Modality\": [],\n",
    "        \"Vocal Channel\": [],\n",
    "        \"Emotion\": [],\n",
    "        \"Emotional Intensity\": [],\n",
    "        \"Statement\": [],\n",
    "        \"Repetition\": [],\n",
    "        \"Sex\": [],\n",
    "    }\n",
    "    file_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(ravdess_path)\n",
    "        for file in files\n",
    "        if file.endswith(\".wav\")\n",
    "    ]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        duration = segment_duration if truncate else None\n",
    "        speech, sr = librosa.load(file_path, sr=sr, mono=True, duration=duration)\n",
    "        speech = separate_vocals(speech, sr, filter_duration, top_db)\n",
    "        if pad_zero and len(speech) < segment_duration * sr:\n",
    "            padding_length = segment_duration * sr - len(speech)\n",
    "            speech = np.pad(speech, (0, padding_length), mode=\"constant\", constant_values=0.0)\n",
    "\n",
    "        if persistency:\n",
    "            emotion = int(file_name[6:8])\n",
    "            with open(os.path.join(ravdess_path, \"data.tsv\"), mode=\"a\", newline=\"\") as persist_file:\n",
    "                tsv_writer = csv.writer(persist_file, delimiter=\"\\t\")\n",
    "                tsv_writer.writerow([emotion] + np.round(speech, 7).tolist())\n",
    "\n",
    "        data[\"File Name\"].append(file_name[:-4])\n",
    "        data[\"Duration\"].append(len(speech) / sr)\n",
    "        data[\"Modality\"].append(coded_ravdess[\"modalities\"].get(file_name[:2]))\n",
    "        data[\"Vocal Channel\"].append(coded_ravdess[\"vocal_channels\"].get(file_name[3:5]))\n",
    "        data[\"Emotion\"].append(coded_ravdess[\"emotions\"].get(file_name[6:8]))\n",
    "        data[\"Emotional Intensity\"].append(coded_ravdess[\"emotional_intensities\"].get(file_name[9:11]))\n",
    "        data[\"Statement\"].append(coded_ravdess[\"statements\"].get(file_name[12:14]))\n",
    "        data[\"Repetition\"].append(coded_ravdess[\"repetitions\"].get(file_name[15:17]))\n",
    "        data[\"Sex\"].append(\"Male\" if int(file_name[18:20]) % 2 else \"Female\")\n",
    "\n",
    "    info = pd.DataFrame(data)\n",
    "\n",
    "    if persistency:\n",
    "        info.to_csv(os.path.join(ravdess_path, \"info.csv\"), index=False)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emodb(\n",
    "    emodb_path: str = EMODB_PATH,\n",
    "    sr: int = SR,\n",
    "    segment_duration: float = SEGMENT_DURATION,\n",
    "    filter_duration: float = 0.5,\n",
    "    top_db: int = 60,\n",
    "    pad_zero: bool = PAD_ZERO,\n",
    "    truncate: bool = TRUNCATE,\n",
    "    coded_emodb: Dict = CODED_EMODB,\n",
    "    persistency: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List]:\n",
    "    if persistency:\n",
    "        with open(os.path.join(emodb_path, \"data.tsv\"), mode=\"w\") as f:\n",
    "            f.truncate()\n",
    "\n",
    "    data = {\n",
    "        \"File Name\": [],\n",
    "        \"Duration\": [],\n",
    "        \"Sex\": [],\n",
    "        \"Age\": [],\n",
    "        \"Text\": [],\n",
    "        \"Emotion\": [],\n",
    "    }\n",
    "    file_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(emodb_path)\n",
    "        for file in files\n",
    "        if file.endswith(\".wav\")\n",
    "    ]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        duration = segment_duration if truncate else None\n",
    "        speech, sr = librosa.load(file_path, sr=sr, mono=True, duration=duration)\n",
    "        speech = separate_vocals(speech, sr, filter_duration, top_db)\n",
    "        if pad_zero and len(speech) < segment_duration * sr:\n",
    "            padding_length = segment_duration * sr - len(speech)\n",
    "            speech = np.pad(\n",
    "                speech, (0, padding_length), mode=\"constant\", constant_values=0.0\n",
    "            )\n",
    "\n",
    "        if persistency:\n",
    "            emotion = (\n",
    "                list(coded_emodb[\"emotions\"].keys()).index(file_name[5])\n",
    "                if file_name[5] in coded_emodb[\"emotions\"]\n",
    "                else -1\n",
    "            )\n",
    "            with open(os.path.join(emodb_path, \"data.tsv\"), mode=\"a\", newline=\"\") as persist_file:\n",
    "                tsv_writer = csv.writer(persist_file, delimiter=\"\\t\")\n",
    "                tsv_writer.writerow([emotion] + np.round(speech, 7).tolist())\n",
    "\n",
    "        data[\"File Name\"].append(file_name[:-4])\n",
    "        data[\"Duration\"].append(len(speech) / sr)\n",
    "        data[\"Sex\"].append(coded_emodb[\"actors\"].get(file_name[:2], [None, None])[0])\n",
    "        data[\"Age\"].append(coded_emodb[\"actors\"].get(file_name[:2], [None, None])[1])\n",
    "        data[\"Text\"].append(file_name[2:5])\n",
    "        data[\"Emotion\"].append(coded_emodb[\"emotions\"].get(file_name[5]))\n",
    "\n",
    "    info = pd.DataFrame(data)\n",
    "\n",
    "    if persistency:\n",
    "        info.to_csv(os.path.join(emodb_path, \"info.csv\"), index=False)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    ravdess_info = read_ravdess(pad_zero=False, truncate=False, persistency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    ravdess_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "\n",
    "    plt.boxplot(ravdess_info[\"Duration\"], showmeans=True)\n",
    "\n",
    "    plt.title(\"Distribution of RAVDESS Durations\", fontsize=16, weight=\"bold\")\n",
    "    plt.xlabel(\"RAVDESS Data\", fontsize=14)\n",
    "    plt.ylabel(\"Duration (seconds)\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks([1], [\"Durations\"], fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(RAVDESS_PATH, \"Durations Box Plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Durations Box Plot](<.\\datasets\\RAVDESS\\Durations Box Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "\n",
    "    ravdess_info[\"Emotion\"].value_counts().plot.bar(rot=0)\n",
    "\n",
    "    plt.title(\"Distribution of RAVDESS Emotions\", fontsize=16, weight=\"bold\")\n",
    "    plt.ylabel(\"Count\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(RAVDESS_PATH, \"Count plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Count Plot.png](<.\\datasets\\RAVDESS\\Count Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc07f060f7a4898b76b24fba2fad639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not preliminary:\n",
    "    ravdess_info = read_ravdess(segment_duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85db406a59a54b719bcbb548bc1c7f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not preliminary:\n",
    "    chunks = pd.read_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"data.tsv\"),\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "\n",
    "    chunk_list = []\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    data = pd.concat(chunk_list, axis=0)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        data, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data.iloc[:, 0]\n",
    "    )\n",
    "\n",
    "    train_data.to_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"RAVDESS_TRAIN.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "    test_data.to_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"RAVDESS_TEST.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    emodb_info = read_emodb(pad_zero=False, truncate=False, persistency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    emodb_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "\n",
    "    plt.boxplot(emodb_info[\"Duration\"], showmeans=True)\n",
    "\n",
    "    plt.title(\"Distribution of EmoDB Durations\", fontsize=16, weight=\"bold\")\n",
    "    plt.xlabel(\"EmoDB Data\", fontsize=14)\n",
    "    plt.ylabel(\"Duration (seconds)\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks([1], [\"Durations\"], fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(EMODB_PATH, \"Durations Box Plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Durations Box Plot](<.\\datasets\\EmoDB\\Durations Box Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "\n",
    "    emodb_info[\"Emotion\"].value_counts().plot.bar(rot=0)\n",
    "\n",
    "    plt.title(\"Distribution of EmoDB Emotions\", fontsize=16, weight=\"bold\")\n",
    "    plt.ylabel(\"Count\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(EMODB_PATH, \"Count plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Count plot.png](<.\\datasets\\EmoDB\\Count Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dff3759218a4ab891bedc03626b33c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/535 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not preliminary:\n",
    "    emodb_info = read_emodb(segment_duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774dbf14107f4174b53b449305a0ef50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not preliminary:\n",
    "    chunks = pd.read_csv(\n",
    "        os.path.join(EMODB_PATH, \"data.tsv\"),\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "\n",
    "    chunk_list = []\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    data = pd.concat(chunk_list, axis=0)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        data, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data.iloc[:, 0]\n",
    "    )\n",
    "\n",
    "    train_data.to_csv(\n",
    "        os.path.join(EMODB_PATH, \"EmoDB_TRAIN.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "    test_data.to_csv(\n",
    "        os.path.join(EMODB_PATH, \"EmoDB_TEST.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.000181  0.010139  0.009276  0.005066  0.010810  0.004045  0.004757   \n",
      "1  0.001094  0.004550  0.002879  0.002247  0.003305  0.002416  0.001619   \n",
      "2  0.003531  0.002285 -0.000420 -0.003738 -0.006706 -0.003148  0.000733   \n",
      "3 -0.001772 -0.001311  0.000388  0.000408 -0.000355  0.000998  0.001109   \n",
      "4  0.000087 -0.000272  0.001022  0.003126  0.002284  0.000885  0.001933   \n",
      "\n",
      "          7         8         9  ...       119       120       121       122  \\\n",
      "0  0.006214  0.003307  0.007572  ... -0.006891 -0.004903  0.001354  0.008033   \n",
      "1  0.000981  0.000009 -0.000363  ...  0.018556  0.018173  0.018046  0.019393   \n",
      "2  0.000668  0.002162 -0.000946  ... -0.002691 -0.000283  0.000404 -0.001556   \n",
      "3 -0.003149 -0.008882 -0.010483  ... -0.011208 -0.013223 -0.013121 -0.012114   \n",
      "4  0.002270  0.002247  0.002175  ...  0.009031  0.009103  0.005473  0.003101   \n",
      "\n",
      "        123       124       125       126       127  label  \n",
      "0  0.007355  0.002669 -0.002170 -0.005643 -0.001446      5  \n",
      "1  0.018070  0.014628  0.005045 -0.004424 -0.002798      5  \n",
      "2 -0.001239 -0.003032 -0.005566 -0.003702 -0.002645      5  \n",
      "3 -0.009983 -0.007534 -0.008408 -0.011158 -0.012987      5  \n",
      "4  0.000470 -0.006906 -0.004491 -0.003441 -0.010082      5  \n",
      "\n",
      "[5 rows x 769 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Load testing data\\ntest_signals = load_inertial_signals(test_signals_folder, train=False)\\ntest_labels = load_labels(test_labels_file)\\ntest_data = combine_signals_and_labels(test_signals, test_labels)\\n\\n# Save data to ts file\\ntrain_file = root + 'HAR_TRAIN.ts'\\ntest_file = root + 'HAR_TEST.ts'\\nsave_time_series_to_ts_file(train_data, train_file)\\nsave_time_series_to_ts_file(test_data, test_file)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_inertial_signals(folder_path, train=True):\n",
    "    \"\"\"\n",
    "    Load inertial signals for each axis of the body accelerometer and gyroscope.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing the inertial signals.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are sensor axes (e.g., 'body_acc_x') and values are DataFrames.\n",
    "    \"\"\"\n",
    "    if train == True:\n",
    "        signal_files = [\n",
    "        'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt',\n",
    "        'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt'\n",
    "        ]\n",
    "    else:\n",
    "        signal_files = [\n",
    "        'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt',\n",
    "        'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt'\n",
    "        ]\n",
    "    \n",
    "    signals = {}\n",
    "    \n",
    "    for file in signal_files:\n",
    "        signal_name = file.split('_')[1] + \"_\" + file.split('_')[2]  # body_acc, body_gyro, etc.\n",
    "        file_path = folder_path + '/' + file\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Read the signal file into a DataFrame\n",
    "            signal_data = pd.read_csv(file_path, header=None, sep=r'\\s+', engine='python')\n",
    "            signals[signal_name] = signal_data\n",
    "        else:\n",
    "            print(f\"File {file_path} not found!\")\n",
    "    \n",
    "    return signals\n",
    "\n",
    "def load_labels(label_file_path):\n",
    "    \"\"\"\n",
    "    Load the activity labels (e.g., y_train.txt).\n",
    "    \n",
    "    Parameters:\n",
    "        label_file_path (str): Path to the label file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: A pandas series containing the activity labels.\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(label_file_path, header=None)\n",
    "    return labels.to_numpy().ravel()\n",
    "\n",
    "def combine_signals_and_labels(signals, labels):\n",
    "    \"\"\"\n",
    "    Combine the inertial signals and activity labels into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        signals (dict): Dictionary containing signal DataFrames for each sensor.\n",
    "        labels (pd.Series): Series containing the activity labels.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with all the signals and labels combined.\n",
    "    \"\"\"\n",
    "    # Combine all signals into one DataFrame (along columns)\n",
    "    combined_signals = pd.concat(signals.values(), axis=1)\n",
    "    \n",
    "    # Add the labels as the last column\n",
    "    combined_signals['label'] = labels\n",
    "    \n",
    "    return combined_signals\n",
    "\n",
    "def save_time_series_to_ts_file(data, output_file):\n",
    "    \"\"\"\n",
    "    Save the combined time series data to a .ts file in the format var1:var2:label.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing the combined signals and labels.\n",
    "        output_file (str): Path to save the .ts file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for index, row in data.iterrows():\n",
    "            # Format each row as var1:var2:label\n",
    "            formatted_row = ':'.join(map(str, row[:-1])) + f\":{row['label']}\\n\"\n",
    "            f.write(formatted_row)\n",
    "\n",
    "# Define paths\n",
    "root = 'datasets/HAR/'\n",
    "train_signals_folder = root + 'train/Inertial Signals'\n",
    "test_signals_folder = root + 'test/Inertial Signals'\n",
    "train_labels_file = root + 'train/y_train.txt'\n",
    "test_labels_file = root + 'test/y_test.txt'\n",
    "\n",
    "# Load training data\n",
    "train_signals = load_inertial_signals(train_signals_folder, train=True)\n",
    "train_labels = load_labels(train_labels_file)\n",
    "train_data = combine_signals_and_labels(train_signals, train_labels)\n",
    "print(train_data.head())\n",
    "'''\n",
    "# Load testing data\n",
    "test_signals = load_inertial_signals(test_signals_folder, train=False)\n",
    "test_labels = load_labels(test_labels_file)\n",
    "test_data = combine_signals_and_labels(test_signals, test_labels)\n",
    "\n",
    "# Save data to ts file\n",
    "train_file = root + 'HAR_TRAIN.ts'\n",
    "test_file = root + 'HAR_TEST.ts'\n",
    "save_time_series_to_ts_file(train_data, train_file)\n",
    "save_time_series_to_ts_file(test_data, test_file)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_inertial_signals(folder_path, train=True):\n",
    "    \"\"\"\n",
    "    Load inertial signals for each axis of the body accelerometer and gyroscope.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to the folder containing the inertial signals.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are sensor axes (e.g., 'body_acc_x') and values are DataFrames.\n",
    "    \"\"\"\n",
    "    if train == True:\n",
    "        signal_files = [\n",
    "        'body_acc_x_train.txt', 'body_acc_y_train.txt', 'body_acc_z_train.txt',\n",
    "        'body_gyro_x_train.txt', 'body_gyro_y_train.txt', 'body_gyro_z_train.txt'\n",
    "        ]\n",
    "    else:\n",
    "        signal_files = [\n",
    "        'body_acc_x_test.txt', 'body_acc_y_test.txt', 'body_acc_z_test.txt',\n",
    "        'body_gyro_x_test.txt', 'body_gyro_y_test.txt', 'body_gyro_z_test.txt'\n",
    "        ]\n",
    "    \n",
    "    signals = {}\n",
    "    \n",
    "    for file in signal_files:\n",
    "        signal_name = file.split('_')[1] + \"_\" + file.split('_')[2]  # body_acc, body_gyro, etc.\n",
    "        file_path = folder_path + '/' + file\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Read the signal file into a DataFrame\n",
    "            signal_data = pd.read_csv(file_path, header=None, sep=r'\\s+', engine='python')\n",
    "            signals[signal_name] = signal_data\n",
    "        else:\n",
    "            print(f\"File {file_path} not found!\")\n",
    "    \n",
    "    return signals\n",
    "\n",
    "def load_labels(label_file_path):\n",
    "    \"\"\"\n",
    "    Load the activity labels (e.g., y_train.txt).\n",
    "    \n",
    "    Parameters:\n",
    "        label_file_path (str): Path to the label file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: A pandas series containing the activity labels.\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(label_file_path, header=None)\n",
    "    return labels.to_numpy().ravel()\n",
    "\n",
    "def combine_signals_and_labels(signals, labels):\n",
    "    \"\"\"\n",
    "    Combine the inertial signals and activity labels into a single DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        signals (dict): Dictionary containing signal DataFrames for each sensor.\n",
    "        labels (pd.Series): Series containing the activity labels.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with all the signals and labels combined.\n",
    "    \"\"\"\n",
    "    # Combine all signals into one DataFrame (along columns)\n",
    "    combined_signals = pd.concat(signals.values(), axis=1)\n",
    "    \n",
    "    # Add the labels as the last column\n",
    "    combined_signals['label'] = labels\n",
    "    \n",
    "    return combined_signals\n",
    "\n",
    "def save_time_series_to_ts_file(data, output_file):\n",
    "    \"\"\"\n",
    "    Save the combined time series data to a .ts file in the format var1_values:var2_values:label.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing the combined signals and labels.\n",
    "        output_file (str): Path to save the .ts file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        for index, row in data.iterrows():\n",
    "            # Format each row as var1_values:var2_values:label\n",
    "            time_series_values = ':'.join([','.join(map(str, row[i])) for i in range(len(row) - 1)])\n",
    "            formatted_row = f\"{time_series_values}:{row['label']}\\n\"\n",
    "            f.write(formatted_row)\n",
    "\n",
    "# Define paths\n",
    "root = 'datasets/HAR/'\n",
    "train_signals_folder = root + 'train/Inertial Signals'\n",
    "test_signals_folder = root + 'test/Inertial Signals'\n",
    "train_labels_file = root + 'train/y_train.txt'\n",
    "test_labels_file = root + 'test/y_test.txt'\n",
    "\n",
    "# Load training data\n",
    "train_signals = load_inertial_signals(train_signals_folder, train=True)\n",
    "train_labels = load_labels(train_labels_file)\n",
    "train_data = combine_signals_and_labels(train_signals, train_labels)\n",
    "\n",
    "# Load testing data\n",
    "test_signals = load_inertial_signals(test_signals_folder, train=False)\n",
    "test_labels = load_labels(test_labels_file)\n",
    "test_data = combine_signals_and_labels(test_signals, test_labels)\n",
    "\n",
    "# Save data to ts file\n",
    "train_file = root + 'HAR_TRAIN.ts'\n",
    "test_file = root + 'HAR_TEST.ts'\n",
    "save_time_series_to_ts_file(train_data, train_file)\n",
    "save_time_series_to_ts_file(test_data, test_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
