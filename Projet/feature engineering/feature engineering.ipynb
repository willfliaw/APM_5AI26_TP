{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project assumes the following initial file structure:\n",
    "\n",
    "```bash\n",
    "./feature_engineering                         \n",
    "|   preprocessing.ipynb                       \n",
    "|                                             \n",
    "\\---datasets                                  \n",
    "    |                                         \n",
    "    +---EmoDB                                 \n",
    "    |   |   erkennung.txt                     \n",
    "    |   |   erklaerung.txt                    \n",
    "    |   |                                     \n",
    "    |   +---lablaut                           \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   +---labsilb                           \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   +---silb                              \n",
    "    |   |       ...                           \n",
    "    |   |                                     \n",
    "    |   \\---wav                               \n",
    "    |           03a01Fa.wav                   \n",
    "    |           03a01Nc.wav                   \n",
    "    |           ...                           \n",
    "    |                                         \n",
    "    \\---RAVDESS                               \n",
    "        |                                     \n",
    "        +---song                              \n",
    "        |   +---Actor_01                      \n",
    "        |   |       03-02-01-01-01-01-01.wav  \n",
    "        |   |       03-02-01-01-01-02-01.wav  \n",
    "        |   |       ...                       \n",
    "        |   |                                 \n",
    "        |   +---Actor_02                      \n",
    "        |   |       03-02-01-01-01-01-02.wav  \n",
    "        |   |       03-02-01-01-01-02-02.wav  \n",
    "        |   |       ...                       \n",
    "        |   |                                 \n",
    "        |   +---...                           \n",
    "        |   \\---Actor_24                      \n",
    "        |           03-02-01-01-01-01-24.wav  \n",
    "        |           03-02-01-01-01-02-24.wav  \n",
    "        |           ...                       \n",
    "        |                                     \n",
    "        \\---speech                            \n",
    "            +---Actor_01                      \n",
    "            |       03-01-01-01-01-01-01.wav  \n",
    "            |       03-01-01-01-01-02-01.wav  \n",
    "            |       ...                       \n",
    "            +---Actor_02                      \n",
    "            |       03-01-01-01-01-01-02.wav  \n",
    "            |       03-01-01-01-01-02-02.wav  \n",
    "            |       ...                       \n",
    "            |                                 \n",
    "            +---...                           \n",
    "            \\---Actor_24                      \n",
    "                    03-01-01-01-01-01-24.wav  \n",
    "                    03-01-01-01-01-02-24.wav  \n",
    "                    ...                       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import importlib.metadata\n",
    "import os\n",
    "import types\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import librosa  # https://github.com/librosa/librosa/issues/1776\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current module versions in use are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for dist in importlib.metadata.distributions():\n",
    "    if (\n",
    "        dist.metadata[\"Name\"].lower() in imports\n",
    "        and dist.metadata[\"Name\"].lower() != \"pip\"\n",
    "    ):\n",
    "        requirements.append((dist.metadata[\"Name\"], dist.version))\n",
    "\n",
    "pd.DataFrame(requirements, columns=[\"Module\", \"Version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./datasets\"\n",
    "SR = 8000\n",
    "SEGMENT_DURATION = 3\n",
    "PAD_ZERO = True\n",
    "TRUNCATE = True\n",
    "RAVDESS_PATH = os.path.join(DATA_PATH, \"RAVDESS\")\n",
    "CODED_RAVDESS = {\n",
    "    \"modalities\": {\"01\": \"full-AV\", \"02\": \"video-only\", \"03\": \"audio-only\"},\n",
    "    \"vocal_channels\": {\"01\": \"speech\", \"02\": \"song\"},\n",
    "    \"emotions\": {\n",
    "        \"01\": \"neutral\",\n",
    "        \"02\": \"calm\",\n",
    "        \"03\": \"happy\",\n",
    "        \"04\": \"sad\",\n",
    "        \"05\": \"angry\",\n",
    "        \"06\": \"fearful\",\n",
    "        \"07\": \"disgust\",\n",
    "        \"08\": \"surprised\",\n",
    "    },\n",
    "    \"emotional_intensities\": {\"01\": \"normal\", \"02\": \"strong\"},\n",
    "    \"statements\": {\n",
    "        \"01\": \"Kids are talking by the door\",\n",
    "        \"02\": \"Dogs are sitting by the door\",\n",
    "    },\n",
    "    \"repetitions\": {\"01\": \"1st repetition\", \"02\": \"2nd repetition\"},\n",
    "}\n",
    "EMODB_PATH = os.path.join(DATA_PATH, \"EmoDB\")\n",
    "CODED_EMODB = {\n",
    "    \"actors\": {\n",
    "        \"03\": (\"Male\", 31),\n",
    "        \"08\": (\"Female\", 34),\n",
    "        \"09\": (\"Female\", 21),\n",
    "        \"10\": (\"Male\", 32),\n",
    "        \"11\": (\"Male\", 26),\n",
    "        \"12\": (\"Male\", 30),\n",
    "        \"13\": (\"Female\", 32),\n",
    "        \"14\": (\"Female\", 35),\n",
    "        \"15\": (\"Male\", 25),\n",
    "        \"16\": (\"Female\", 31),\n",
    "    },\n",
    "    \"texts\": {\n",
    "        \"a01\": \"Der Lappen liegt auf dem Eisschrank.\",\n",
    "        \"a02\": \"Das will sie am Mittwoch abgeben.\",\n",
    "        \"a04\": \"Heute abend könnte ich es ihm sagen.\",\n",
    "        \"a05\": \"Das schwarze Stück Papier befindet sich da oben neben dem Holzstück.\",\n",
    "        \"a07\": \"In sieben Stunden wird es soweit sein.\",\n",
    "        \"b01\": \"Was sind denn das für Tüten, die da unter dem Tisch stehen?\",\n",
    "        \"b02\": \"Sie haben es gerade hochgetragen und jetzt gehen sie wieder runter.\",\n",
    "        \"b03\": \"An den Wochenenden bin ich jetzt immer nach Hause gefahren und habe Agnes besucht.\",\n",
    "        \"b09\": \"Ich will das eben wegbringen und dann mit Karl was trinken gehen.\",\n",
    "        \"b10\": \"Die wird auf dem Platz sein, wo wir sie immer hinlegen.\",\n",
    "    },\n",
    "    \"emotions\": {\n",
    "        \"W\": \"Anger\",\n",
    "        \"L\": \"Boredom\",\n",
    "        \"E\": \"Disgust\",\n",
    "        \"A\": \"Anxiety/Fear\",\n",
    "        \"F\": \"Happiness\",\n",
    "        \"T\": \"Sadness\",\n",
    "        \"N\": \"Neutral\",\n",
    "    },\n",
    "}\n",
    "CHUNK_SIZE = 10\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_vocals(\n",
    "    speech: np.ndarray,\n",
    "    sr: int = SR,\n",
    "    filter_duration: float = 0.75,\n",
    "    top_db: int = 60,\n",
    ") -> np.ndarray:\n",
    "    S_full, phase = librosa.magphase(librosa.stft(speech))\n",
    "    S_filter = librosa.decompose.nn_filter(\n",
    "        S_full,\n",
    "        aggregate=np.median,\n",
    "        metric=\"cosine\",\n",
    "        width=int(librosa.time_to_frames(filter_duration, sr=sr)),\n",
    "    )\n",
    "    S_filter = np.minimum(S_full, S_filter)\n",
    "    mask_v = librosa.util.softmask(S_full - S_filter, 10 * S_filter, power=2)\n",
    "    speech = librosa.istft(mask_v * S_full * phase)\n",
    "    indexes = librosa.effects.split(speech, top_db=top_db)\n",
    "    speech = np.array(\n",
    "        [num for arr in (speech[i[0] : i[1]] for i in indexes) for num in arr.tolist()]\n",
    "    )\n",
    "\n",
    "    return speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ravdess(\n",
    "    ravdess_path: str = RAVDESS_PATH,\n",
    "    sr: int = SR,\n",
    "    segment_duration: float = SEGMENT_DURATION,\n",
    "    filter_duration: float = 0.75,\n",
    "    top_db: int = 60,\n",
    "    pad_zero: bool = PAD_ZERO,\n",
    "    truncate: bool = TRUNCATE,\n",
    "    coded_ravdess: Dict = CODED_RAVDESS,\n",
    "    persistency: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List]:\n",
    "\n",
    "    if persistency:\n",
    "        with open(os.path.join(ravdess_path, \"data.tsv\"), mode=\"w\") as f:\n",
    "            f.truncate()\n",
    "\n",
    "    data = {\n",
    "        \"File Name\": [],\n",
    "        \"Duration\": [],\n",
    "        \"Modality\": [],\n",
    "        \"Vocal Channel\": [],\n",
    "        \"Emotion\": [],\n",
    "        \"Emotional Intensity\": [],\n",
    "        \"Statement\": [],\n",
    "        \"Repetition\": [],\n",
    "        \"Sex\": [],\n",
    "    }\n",
    "    file_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(ravdess_path)\n",
    "        for file in files\n",
    "        if file.endswith(\".wav\")\n",
    "    ]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        duration = segment_duration if truncate else None\n",
    "        speech, sr = librosa.load(file_path, sr=sr, mono=True, duration=duration)\n",
    "        speech = separate_vocals(speech, sr, filter_duration, top_db)\n",
    "        if pad_zero and len(speech) < segment_duration * sr:\n",
    "            padding_length = segment_duration * sr - len(speech)\n",
    "            speech = np.pad(speech, (0, padding_length), mode=\"constant\", constant_values=0.0)\n",
    "\n",
    "        if persistency:\n",
    "            emotion = int(file_name[6:8])\n",
    "            with open(os.path.join(ravdess_path, \"data.tsv\"), mode=\"a\", newline=\"\") as persist_file:\n",
    "                tsv_writer = csv.writer(persist_file, delimiter=\"\\t\")\n",
    "                tsv_writer.writerow([emotion] + np.round(speech, 7).tolist())\n",
    "\n",
    "        data[\"File Name\"].append(file_name[:-4])\n",
    "        data[\"Duration\"].append(len(speech) / sr)\n",
    "        data[\"Modality\"].append(coded_ravdess[\"modalities\"].get(file_name[:2]))\n",
    "        data[\"Vocal Channel\"].append(coded_ravdess[\"vocal_channels\"].get(file_name[3:5]))\n",
    "        data[\"Emotion\"].append(coded_ravdess[\"emotions\"].get(file_name[6:8]))\n",
    "        data[\"Emotional Intensity\"].append(coded_ravdess[\"emotional_intensities\"].get(file_name[9:11]))\n",
    "        data[\"Statement\"].append(coded_ravdess[\"statements\"].get(file_name[12:14]))\n",
    "        data[\"Repetition\"].append(coded_ravdess[\"repetitions\"].get(file_name[15:17]))\n",
    "        data[\"Sex\"].append(\"Male\" if int(file_name[18:20]) % 2 else \"Female\")\n",
    "\n",
    "    info = pd.DataFrame(data)\n",
    "\n",
    "    if persistency:\n",
    "        info.to_csv(os.path.join(ravdess_path, \"info.csv\"), index=False)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emodb(\n",
    "    emodb_path: str = EMODB_PATH,\n",
    "    sr: int = SR,\n",
    "    segment_duration: float = SEGMENT_DURATION,\n",
    "    filter_duration: float = 0.5,\n",
    "    top_db: int = 60,\n",
    "    pad_zero: bool = PAD_ZERO,\n",
    "    truncate: bool = TRUNCATE,\n",
    "    coded_emodb: Dict = CODED_EMODB,\n",
    "    persistency: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List]:\n",
    "    if persistency:\n",
    "        with open(os.path.join(emodb_path, \"data.tsv\"), mode=\"w\") as f:\n",
    "            f.truncate()\n",
    "\n",
    "    data = {\n",
    "        \"File Name\": [],\n",
    "        \"Duration\": [],\n",
    "        \"Sex\": [],\n",
    "        \"Age\": [],\n",
    "        \"Text\": [],\n",
    "        \"Emotion\": [],\n",
    "    }\n",
    "    file_paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(emodb_path)\n",
    "        for file in files\n",
    "        if file.endswith(\".wav\")\n",
    "    ]\n",
    "    for file_path in tqdm(file_paths):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        duration = segment_duration if truncate else None\n",
    "        speech, sr = librosa.load(file_path, sr=sr, mono=True, duration=duration)\n",
    "        speech = separate_vocals(speech, sr, filter_duration, top_db)\n",
    "        if pad_zero and len(speech) < segment_duration * sr:\n",
    "            padding_length = segment_duration * sr - len(speech)\n",
    "            speech = np.pad(\n",
    "                speech, (0, padding_length), mode=\"constant\", constant_values=0.0\n",
    "            )\n",
    "\n",
    "        if persistency:\n",
    "            emotion = (\n",
    "                list(coded_emodb[\"emotions\"].keys()).index(file_name[5])\n",
    "                if file_name[5] in coded_emodb[\"emotions\"]\n",
    "                else -1\n",
    "            )\n",
    "            with open(os.path.join(emodb_path, \"data.tsv\"), mode=\"a\", newline=\"\") as persist_file:\n",
    "                tsv_writer = csv.writer(persist_file, delimiter=\"\\t\")\n",
    "                tsv_writer.writerow([emotion] + np.round(speech, 7).tolist())\n",
    "\n",
    "        data[\"File Name\"].append(file_name[:-4])\n",
    "        data[\"Duration\"].append(len(speech) / sr)\n",
    "        data[\"Sex\"].append(coded_emodb[\"actors\"].get(file_name[:2], [None, None])[0])\n",
    "        data[\"Age\"].append(coded_emodb[\"actors\"].get(file_name[:2], [None, None])[1])\n",
    "        data[\"Text\"].append(file_name[2:5])\n",
    "        data[\"Emotion\"].append(coded_emodb[\"emotions\"].get(file_name[5]))\n",
    "\n",
    "    info = pd.DataFrame(data)\n",
    "\n",
    "    if persistency:\n",
    "        info.to_csv(os.path.join(emodb_path, \"info.csv\"), index=False)\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    ravdess_info = read_ravdess(pad_zero=False, truncate=False, persistency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    ravdess_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "\n",
    "    plt.boxplot(ravdess_info[\"Duration\"], showmeans=True)\n",
    "\n",
    "    plt.title(\"Distribution of RAVDESS Durations\", fontsize=16, weight=\"bold\")\n",
    "    plt.xlabel(\"RAVDESS Data\", fontsize=14)\n",
    "    plt.ylabel(\"Duration (seconds)\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks([1], [\"Durations\"], fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(RAVDESS_PATH, \"Durations Box Plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Durations Box Plot](<.\\datasets\\RAVDESS\\Durations Box Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "\n",
    "    ravdess_info[\"Emotion\"].value_counts().plot.bar(rot=0)\n",
    "\n",
    "    plt.title(\"Distribution of RAVDESS Emotions\", fontsize=16, weight=\"bold\")\n",
    "    plt.ylabel(\"Count\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(RAVDESS_PATH, \"Count plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Count Plot.png](<.\\datasets\\RAVDESS\\Count Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preliminary:\n",
    "    ravdess_info = read_ravdess(segment_duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preliminary:\n",
    "    chunks = pd.read_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"data.tsv\"),\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "\n",
    "    chunk_list = []\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    data = pd.concat(chunk_list, axis=0)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        data, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data.iloc[:, 0]\n",
    "    )\n",
    "\n",
    "    train_data.to_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"RAVDESS_TRAIN.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "    test_data.to_csv(\n",
    "        os.path.join(RAVDESS_PATH, \"RAVDESS_TEST.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preliminary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    emodb_info = read_emodb(pad_zero=False, truncate=False, persistency=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    emodb_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "\n",
    "    plt.boxplot(emodb_info[\"Duration\"], showmeans=True)\n",
    "\n",
    "    plt.title(\"Distribution of EmoDB Durations\", fontsize=16, weight=\"bold\")\n",
    "    plt.xlabel(\"EmoDB Data\", fontsize=14)\n",
    "    plt.ylabel(\"Duration (seconds)\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks([1], [\"Durations\"], fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(EMODB_PATH, \"Durations Box Plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Durations Box Plot](<.\\datasets\\EmoDB\\Durations Box Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preliminary:\n",
    "    plt.figure(figsize=(7, 5), dpi=80)\n",
    "\n",
    "    emodb_info[\"Emotion\"].value_counts().plot.bar(rot=0)\n",
    "\n",
    "    plt.title(\"Distribution of EmoDB Emotions\", fontsize=16, weight=\"bold\")\n",
    "    plt.ylabel(\"Count\", fontsize=14)\n",
    "\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(EMODB_PATH, \"Count plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Count plot.png](<.\\datasets\\EmoDB\\Count Plot.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preliminary:\n",
    "    emodb_info = read_emodb(segment_duration=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not preliminary:\n",
    "    chunks = pd.read_csv(\n",
    "        os.path.join(EMODB_PATH, \"data.tsv\"),\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "\n",
    "    chunk_list = []\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    data = pd.concat(chunk_list, axis=0)\n",
    "\n",
    "    train_data, test_data = train_test_split(\n",
    "        data, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=data.iloc[:, 0]\n",
    "    )\n",
    "\n",
    "    train_data.to_csv(\n",
    "        os.path.join(EMODB_PATH, \"EmoDB_TRAIN.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )\n",
    "    test_data.to_csv(\n",
    "        os.path.join(EMODB_PATH, \"EmoDB_TEST.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=False,\n",
    "        chunksize=CHUNK_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inertial_signals(folder_path, train=True):\n",
    "    if train == True:\n",
    "        signal_files = [\n",
    "            \"body_acc_x_train.txt\",\n",
    "            \"body_acc_y_train.txt\",\n",
    "            \"body_acc_z_train.txt\",\n",
    "            \"body_gyro_x_train.txt\",\n",
    "            \"body_gyro_y_train.txt\",\n",
    "            \"body_gyro_z_train.txt\",\n",
    "        ]\n",
    "    else:\n",
    "        signal_files = [\n",
    "            \"body_acc_x_test.txt\",\n",
    "            \"body_acc_y_test.txt\",\n",
    "            \"body_acc_z_test.txt\",\n",
    "            \"body_gyro_x_test.txt\",\n",
    "            \"body_gyro_y_test.txt\",\n",
    "            \"body_gyro_z_test.txt\",\n",
    "        ]\n",
    "\n",
    "    signals = {}\n",
    "\n",
    "    for file in signal_files:\n",
    "        signal_name = (\n",
    "            file.split(\"_\")[1] + \"_\" + file.split(\"_\")[2]\n",
    "        )  # body_acc, body_gyro, etc.\n",
    "        file_path = folder_path + \"/\" + file\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            # Read the signal file into a DataFrame\n",
    "            signal_data = pd.read_csv(\n",
    "                file_path, header=None, sep=r\"\\s+\", engine=\"python\"\n",
    "            )\n",
    "            signals[signal_name] = signal_data\n",
    "        else:\n",
    "            print(f\"File {file_path} not found!\")\n",
    "\n",
    "    return signals\n",
    "\n",
    "\n",
    "def load_labels(label_file_path):\n",
    "    labels = pd.read_csv(label_file_path, header=None)\n",
    "    return labels.to_numpy().flatten()\n",
    "\n",
    "\n",
    "def save_time_series_to_ts_file(data, labels, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        features = list(data.keys())\n",
    "        n = len(data[features[0]])\n",
    "        for i in range(n):\n",
    "            series_data_point = []\n",
    "            for feat in features:\n",
    "                series = data[feat].iloc[i]\n",
    "                # join data in a string\n",
    "                joined_string = \",\".join(map(str, series))\n",
    "                series_data_point.append(joined_string)\n",
    "            # write row to file\n",
    "            formatted_row = \":\".join(map(str, series_data_point)) + f\":{labels[i]}\\n\"\n",
    "            f.write(formatted_row)\n",
    "\n",
    "\n",
    "# Define paths\n",
    "root = \"datasets/HAR/\"\n",
    "train_signals_folder = root + \"train/Inertial Signals\"\n",
    "test_signals_folder = root + \"test/Inertial Signals\"\n",
    "train_labels_file = root + \"train/y_train.txt\"\n",
    "test_labels_file = root + \"test/y_test.txt\"\n",
    "\n",
    "# save training data\n",
    "train_signals = load_inertial_signals(train_signals_folder, train=True)\n",
    "train_labels = load_labels(train_labels_file)\n",
    "save_time_series_to_ts_file(train_signals, train_labels, root + \"HAR_TRAIN.ts\")\n",
    "\n",
    "# save testing data\n",
    "test_signals = load_inertial_signals(test_signals_folder, train=False)\n",
    "test_labels = load_labels(test_labels_file)\n",
    "save_time_series_to_ts_file(test_signals, test_labels, root + \"HAR_TEST.ts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
