@inproceedings{abdullah2020,
  author    = {Abdullah, Muhammad and Ahmad, Mobeen and Han, Dongil},
  booktitle = {2020 International Conference on Electronics, Information, and Communication (ICEIC)},
  title     = {Facial Expression Recognition in Videos: An CNN-LSTM based Model for Video Classification},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-3},
  doi       = {10.1109/ICEIC49074.2020.9051332}
}

@inproceedings{anusha2021,
  author    = {Anusha, R. and Subhashini, P. and Jyothi, Darelli and Harshitha, Potturi and Sushma, Janumpally and Mukesh, Namsamgari},
  booktitle = {2021 5th International Conference on Trends in Electronics and Informatics (ICOEI)},
  title     = {Speech Emotion Recognition using Machine Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1608-1612},
  doi       = {10.1109/ICOEI51242.2021.9453028}
}

@inproceedings{churaev2021,
  author    = {Churaev, Egor and Savchenko, Andrey V.},
  booktitle = {2021 International Russian Automation Conference (RusAutoCon)},
  title     = {Touching the Limits of a Dataset in Video-Based Facial Expression Recognition},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {633-638},
  doi       = {10.1109/RusAutoCon52004.2021.9537388}
}

@inproceedings{emodb,
  author  = {Burkhardt, Felix and Paeschke, Astrid and Rolfes, M. and Sendlmeier, Walter and Weiss, Benjamin},
  year    = {2005},
  month   = {January},
  pages   = {1517-1520},
  title   = {A database of \uppercase{G}erman emotional speech},
  volume  = {5},
  journal = {9th European Conference on Speech Communication and Technology}
}

@inproceedings{felice2023,
  title     = {Time Series Kernels based on Nonlinear Vector AutoRegressive Delay Embeddings},
  author    = {Giovanni De Felice and John Y Goulermas and Vladimir Gusev},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year      = {2023},
  url       = {https://openreview.net/forum?id=UBUWFEwn7p}
}

@book{hamilton1994,
  title   = {Time Series analysis},
  url     = {https://doi.org/10.1515/9780691218632},
  doi     = {10.1515/9780691218632},
  journal = {Princeton University Press eBooks},
  author  = {Hamilton, James Douglas},
  year    = {1994},
  month   = dec
}

@inproceedings{kotti2008,
  author    = {Kotti, Margarita and Kotropoulos, Constantine},
  booktitle = {2008 19th International Conference on Pattern Recognition},
  title     = {Gender classification in two Emotional Speech databases},
  year      = {2008},
  volume    = {},
  number    = {},
  pages     = {1-4},
  doi       = {10.1109/ICPR.2008.4761624}
}

@article{ravdess,
  doi       = {10.1371/journal.pone.0196391},
  author    = {Livingstone, Steven R. AND Russo, Frank A.},
  journal   = {PLOS ONE},
  publisher = {Public Library of Science},
  title     = {The \uppercase{R}yerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in \uppercase{N}orth \uppercase{A}merican \uppercase{E}nglish},
  year      = {2018},
  month     = {05},
  volume    = {13},
  url       = {https://doi.org/10.1371/journal.pone.0196391},
  pages     = {1-35},
  abstract  = {The RAVDESS is a validated multimodal database of emotional speech and song. The database is gender balanced consisting of 24 professional actors, vocalizing lexically-matched statements in a neutral North American accent. Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. Each expression is produced at two levels of emotional intensity, with an additional neutral expression. All conditions are available in face-and-voice, face-only, and voice-only formats. The set of 7356 recordings were each rated 10 times on emotional validity, intensity, and genuineness. Ratings were provided by 247 individuals who were characteristic of untrained research participants from North America. A further set of 72 participants provided test-retest data. High levels of emotional validity and test-retest intrarater reliability were reported. Corrected accuracy and composite "goodness" measures are presented to assist researchers in the selection of stimuli. All recordings are made freely available under a Creative Commons license and can be downloaded at https://doi.org/10.5281/zenodo.1188976.},
  number    = {5}
}

@inproceedings{sinith2015,
  author    = {Sinith, M. S. and Aswathi, E. and Deepa, T. M. and Shameema, C. P. and Rajan, Shiny},
  booktitle = {2015 IEEE Recent Advances in Intelligent Computational Systems (RAICS)},
  title     = {Emotion recognition from audio signals using Support Vector Machine},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {139-144},
  doi       = {10.1109/RAICS.2015.7488403}
}

@inproceedings{vimal2021,
  author    = {Vimal, B. and Surya, Muthyam and Darshan and Sridhar, V.S. and Ashok, Asha},
  booktitle = {2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)},
  title     = {MFCC Based Audio Classification Using Machine Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1-4},
  doi       = {10.1109/ICCCNT51525.2021.9579881}
}

@inproceedings{ying2010,
  author    = {Ying, Sun and Zhang, Xueying},
  booktitle = {2010 First International Conference on Pervasive Computing, Signal Processing and Applications},
  title     = {A Study of Zero-Crossings with Peak-Amplitudes in Speech Emotion Classification},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {328-331},
  doi       = {10.1109/PCSPA.2010.86}
}

@book{strogatz2018,
  title   = {Nonlinear dynamics and chaos},
  url     = {https://doi.org/10.1201/9780429492563},
  doi     = {10.1201/9780429492563},
  journal = {CRC Press eBooks},
  author  = {Strogatz, Steven H.},
  year    = {2018},
  month   = may
}
@book{zhang2017,
  title   = {Multivariate time series analysis in climate and environmental research},
  url     = {https://doi.org/10.1007/978-3-319-67340-0},
  doi     = {10.1007/978-3-319-67340-0},
  journal = {Springer eBooks},
  author  = {Zhang, Zhihua},
  year    = {2017},
  month   = nov
}
@article{zeroual2020,
  title   = {Deep learning methods for forecasting COVID-19 time-Series data: A Comparative study},
  volume  = {140},
  url     = {https://doi.org/10.1016/j.chaos.2020.110121},
  doi     = {10.1016/j.chaos.2020.110121},
  journal = {Chaos Solitons \& Fractals},
  author  = {Zeroual, Abdelhafid and Harrou, Fouzi and Dairi, Abdelkader and Sun, Ying},
  year    = {2020},
  month   = jul,
  pages   = {110121}
}

@article{bollt2021,
  title   = {On explaining the surprising success of reservoir computing forecaster of chaos? The universal machine learning dynamical system with contrast to VAR and DMD},
  volume  = {31},
  url     = {https://pubs.aip.org/aip/cha/article/31/1/013108/341924/On-explaining-the-surprising-success-of-reservoir},
  doi     = {10.1063/5.0024890},
  number  = {1},
  journal = {Chaos an Interdisciplinary Journal of Nonlinear Science},
  author  = {Bollt, Erik},
  year    = {2021},
  month   = jan
}

@article{gauthier2021,
  author     = {Daniel J. Gauthier and
                Erik M. Bollt and
                Aaron Griffith and
                Wendson A. S. Barbosa},
  title      = {Next Generation Reservoir Computing},
  journal    = {CoRR},
  volume     = {abs/2106.07688},
  year       = {2021},
  url        = {https://arxiv.org/abs/2106.07688},
  eprinttype = {arXiv},
  eprint     = {2106.07688},
  timestamp  = {Tue, 25 Oct 2022 16:52:32 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2106-07688.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}
